{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44cc0f12-4c03-46d6-b986-1af9b1841865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherencia del modelo: 0.15146011401832946\n",
      "La visualización LDA se ha guardado en 'lda_visualization_Peña Nieto.html'.\n",
      "Nube de palabras del Tópico 1 guardada como nube_palabras_topico_Peña Nieto_1.png.\n",
      "Nube de palabras del Tópico 2 guardada como nube_palabras_topico_Peña Nieto_2.png.\n",
      "Nube de palabras del Tópico 3 guardada como nube_palabras_topico_Peña Nieto_3.png.\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import unicodedata\n",
    "import pyLDAvis\n",
    "\n",
    "# Lista de stop words personalizadas y comunes en español\n",
    "stopwords = [\n",
    "    'ir', 'hacer', 'año', 'ser', 'decir', 'siento', 'millon', 'mil', 'ahora',\n",
    "    'mexicanos', 'y', 'el', 'hoy', 'aqui', 'mexico', 'dar', 'solo', \n",
    "    'todo', 'deber', 'cada', 'de', 'la', 'en', 'un', 'que', 'a', 'los', \n",
    "    'las', 'con', 'se', 'para', 'por', 'no', 'su', 'este', 'es', 'lo', \n",
    "    'como', 'mas', 'pero', 'al', 'del', 'mi', 'te', 'me', 'si', 'ya', \n",
    "    'cuando', 'otra', 'vez', 'hay', 'estaba', 'tambien', 'asi', 'mismo', 'él',\n",
    "    'mexicano', 'dia', 'ano', 'dos', 'senor'\n",
    "]\n",
    "\n",
    "# Función para normalizar el texto\n",
    "def normalize_text(text):\n",
    "    # Eliminar acentos y convertir el texto a minúsculas\n",
    "    text = ''.join(\n",
    "        char for char in unicodedata.normalize('NFKD', text)\n",
    "        if not unicodedata.combining(char)\n",
    "    ).lower()\n",
    "    \n",
    "    # Dividir el texto en palabras\n",
    "    words = text.split()\n",
    "    \n",
    "    # Eliminar stop words personalizadas (incluyendo 'él' y otros)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Cargar el texto preprocesado\n",
    "with open(\"Enrique_Peñanieto_Procesado.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Dividir el texto en documentos (por ejemplo, por párrafos o líneas)\n",
    "raw_documents = text.split('\\n')  # Asume que cada línea es un documento\n",
    "documents = [normalize_text(doc) for doc in raw_documents if doc.strip()]  # Preprocesar cada documento\n",
    "\n",
    "# Crear el diccionario y el corpus\n",
    "id2word = corpora.Dictionary(documents)  # Crear diccionario\n",
    "corpus = [id2word.doc2bow(doc) for doc in documents]  # Crear el corpus\n",
    "\n",
    "# Entrenar el modelo LDA\n",
    "num_topics = 3  # Ajusta el número de tópicos según tus necesidades\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=42)\n",
    "\n",
    "# Evaluar la coherencia del modelo\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=documents, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Coherencia del modelo: {coherence_lda}\")\n",
    "\n",
    "# Visualizar los tópicos con pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.save_html(vis, 'lda_visualization_Peña Nieto.html')\n",
    "print(\"La visualización LDA se ha guardado en 'lda_visualization_Peña Nieto.html'.\")\n",
    "\n",
    "# Paso 9: Crear y guardar nubes de palabras para cada tópico\n",
    "for idx in range(num_topics):\n",
    "    words = dict(lda_model.show_topic(idx, topn=20))\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(words)\n",
    "    \n",
    "    # Crear la figura\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Tópico {idx + 1}\")\n",
    "    \n",
    "    # Guardar la imagen\n",
    "    filename = f\"nube_palabras_topico_Peña Nieto_{idx + 1}.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()  # Cerrar la figura para liberar memoria\n",
    "\n",
    "    print(f\"Nube de palabras del Tópico {idx + 1} guardada como {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefb6ef-3227-4b2d-be2b-4d13a51aa4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55764101-6d6a-40b2-b1ee-294c31f9b573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
